{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44dbbad8-1184-4496-8437-d4512a0f9ec9",
   "metadata": {},
   "source": [
    "# Code Snippets\n",
    "This notebook walks through the basics of how to use the AI21 models through the Bedrock API; giving a few code snippets you can use in your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa0fee-4bea-4a72-9609-17b5c0fed53e",
   "metadata": {},
   "source": [
    "## Call AI21 Models via Amazon Bedrock API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "Following code snippet shows a call function for Bedrock Converse API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b05b6aa-7e0b-40b2-84aa-62430a5e612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "import logging\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError \n",
    "\n",
    "# Get response from bedrock via Converse API\n",
    "# Support for converse API - https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html\n",
    "def generate_conversation(bedrock_client,\n",
    "                          model_id,\n",
    "                          system_prompts,\n",
    "                          messages):\n",
    "    \"\"\"\n",
    "    Sends messages to a model.\n",
    "    Args:\n",
    "        bedrock_client: The Boto3 Bedrock runtime client.\n",
    "        model_id (str): The model ID to use.\n",
    "        system_prompts (JSON) : The system prompts for the model to use.\n",
    "        messages (JSON) : The messages to send to the model.\n",
    "\n",
    "    Returns:\n",
    "        response (JSON): The conversation that the model generated.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"Generating message with model %s\", model_id)\n",
    "\n",
    "    # Inference parameters to use.\n",
    "    temperature = 0.5\n",
    "    top_p = 1\n",
    "\n",
    "    # Base inference parameters to use.\n",
    "    inference_config = {\"temperature\": temperature}\n",
    "    \n",
    "    # Additional inference parameters to use. For additional information - https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-jamba.html#api-inference-examples-a2i-jamba\n",
    "    additional_model_fields = {\"top_p\": top_p}\n",
    "\n",
    "    # Send the message.\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "    # Log token usage.\n",
    "    token_usage = response['usage']\n",
    "    logging.info(\"Input tokens: %s\", token_usage['inputTokens'])\n",
    "    logging.info(\"Output tokens: %s\", token_usage['outputTokens'])\n",
    "    logging.info(\"Total tokens: %s\", token_usage['totalTokens'])\n",
    "    logging.info(\"Stop reason: %s\", response['stopReason'])\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048ed12",
   "metadata": {},
   "source": [
    "## Call Jamba 1.5\n",
    "Following code snippet shows how to use AI21 Jamba 1.5 model using the converse API call function setup above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jamba 1.5 is only supported in us-east-1 as of 08/20/24\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Entrypoint for foundational model example.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "    # For all model IDs, please visit https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html\n",
    "    model_id = \"ai21.jamba-1-5-large-v1:0\" #Jamba 1.5 Large\n",
    "    #model_id = \"ai21.jamba-1-5-mini-v1:0\" #Jamba 1.5 Mini\n",
    "\n",
    "    # Setup the system prompts and messages to send to the model.\n",
    "    system_prompts = [{\"text\": \"You are an app that creates playlists for a radio station that plays rock and pop music.\"\n",
    "                       \"Only return song names and the artist.\"}]\n",
    "    message_1 = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Create a list of 3 pop songs.\"}]\n",
    "    }\n",
    "    message_2 = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Make sure the songs are by artists from the United Kingdom.\"}]\n",
    "    }\n",
    "    messages = []\n",
    "\n",
    "    try:\n",
    "\n",
    "        bedrock_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "        # Start the conversation with the 1st message.\n",
    "        messages.append(message_1)\n",
    "        response = generate_conversation(\n",
    "            bedrock_client, model_id, system_prompts, messages)\n",
    "\n",
    "        # Add the response message to the conversation.\n",
    "        output_message = response['output']['message']\n",
    "        messages.append(output_message)\n",
    "\n",
    "        # Continue the conversation with the 2nd message.\n",
    "        messages.append(message_2)\n",
    "        response = generate_conversation(\n",
    "            bedrock_client, model_id, system_prompts, messages)\n",
    "\n",
    "        output_message = response['output']['message']\n",
    "        messages.append(output_message)\n",
    "\n",
    "        # Show the complete conversation.\n",
    "        for message in messages:\n",
    "            print(f\"Role: {message['role']}\")\n",
    "            for content in message['content']:\n",
    "                print(f\"Text: {content['text']}\")\n",
    "            print()\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        logging.error(\"A client error occurred: %s\", message)\n",
    "        print(f\"A client error occured: {message}\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            f\"Finished generating text with model {model_id}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140180f4-0ce8-4513-b9f9-785b03df3ee3",
   "metadata": {},
   "source": [
    "## Call Jurassic 2\n",
    "You can also call Jurassic-2 family models using the Bedrock Invoke API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f35a5-dcc3-4083-a4bb-583ea0a29215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock_runtime_client = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "body = json.dumps({\n",
    "    \"prompt\": \"Translate to spanish: 'Amazon Bedrock is the easiest way to build and scale generative AI applications with base models (FMs)'.\", \n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5\n",
    "})\n",
    "\n",
    "modelId = 'ai21.j2-ultra-v1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_runtime_client.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "# text\n",
    "print(response_body.get('completions')[0].get('data').get('text'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
